# V1.0 Implementation Plan (Ruthless Simplicity)

**Version**: 1.0.0  
**Timeline**: 1-3 days  
**Complexity**: ~500 lines of code  
**Status**: Ready to implement

---

## What We're Building

**Core deliverable**: Two tools (`memory_store`, `memory_search`) with semantic search and agent identity isolation.

**What we're NOT building**: Context module, Hook module, migration engine, complex ranking, file storage, scratchpad as separate storage.

---

## Prerequisites

```bash
# Dependencies
pip install qdrant-client openai pydantic
```

---

## Day 1: Storage Infrastructure

### Task 1.1: Project Structure

**Create**:
```bash
cd amplifier-bundle-agent-memory
mkdir -p modules/tool-memory-semantic/memory_semantic
touch modules/tool-memory-semantic/memory_semantic/__init__.py
touch modules/tool-memory-semantic/memory_semantic/models.py
touch modules/tool-memory-semantic/memory_semantic/embeddings.py
touch modules/tool-memory-semantic/memory_semantic/storage.py
touch modules/tool-memory-semantic/memory_semantic/tools.py
```

**pyproject.toml**:
```toml
[project]
name = "amplifier-module-tool-memory-semantic"
version = "1.0.0"
dependencies = [
    "amplifier-core>=0.1.0",
    "qdrant-client>=1.7.0",
    "openai>=1.0.0",
    "pydantic>=2.0",
]
```

**Time**: 30 minutes

---

### Task 1.2: Data Model (models.py)

**File**: `modules/tool-memory-semantic/memory_semantic/models.py`

**Implementation**:
```python
from pydantic import BaseModel, Field
from datetime import datetime
from uuid import uuid4

class Memory(BaseModel):
    """Minimal memory model."""
    id: str = Field(default_factory=lambda: f"mem-{uuid4().hex[:8]}")
    agent_id: str
    content: str
    timestamp: datetime = Field(default_factory=datetime.utcnow)
    embedding: list[float]
    tags: list[str] = []
    
    def dict_for_storage(self):
        """Return dict without embedding for payload."""
        return {
            "id": self.id,
            "agent_id": self.agent_id,
            "content": self.content,
            "timestamp": self.timestamp.isoformat(),
            "tags": self.tags
        }
```

**Validation**:
- [ ] Model instantiates correctly
- [ ] Default ID generation works
- [ ] Timestamp defaults to now

**Time**: 30 minutes

---

### Task 1.3: Embedding Generator (embeddings.py)

**File**: `modules/tool-memory-semantic/memory_semantic/embeddings.py`

**Implementation**:
```python
from openai import AsyncOpenAI
from typing import Optional
import os

class EmbeddingGenerator:
    """OpenAI embedding API wrapper."""
    
    def __init__(
        self,
        model: str = "text-embedding-3-small",
        api_key: Optional[str] = None
    ):
        self.model = model
        self.dimensions = 1536
        self.client = AsyncOpenAI(api_key=api_key or os.getenv("OPENAI_API_KEY"))
    
    async def generate(self, content: str) -> list[float]:
        """Generate embedding for content."""
        response = await self.client.embeddings.create(
            model=self.model,
            input=content
        )
        return response.data[0].embedding
    
    async def generate_batch(self, contents: list[str]) -> list[list[float]]:
        """Batch embedding generation."""
        response = await self.client.embeddings.create(
            model=self.model,
            input=contents
        )
        return [item.embedding for item in response.data]
```

**Validation**:
- [ ] Can generate single embedding
- [ ] Embedding has 1536 dimensions
- [ ] Batch generation works

**Time**: 1 hour (including API setup)

---

### Task 1.4: Storage Layer (storage.py)

**File**: `modules/tool-memory-semantic/memory_semantic/storage.py`

**Implementation**:
```python
from pathlib import Path
from typing import Optional
from datetime import datetime
import re

from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct, Filter

from .models import Memory
from .embeddings import EmbeddingGenerator

class MemoryStorage:
    """Qdrant-based vector storage."""
    
    def __init__(self, agent_id: str, config: dict = None):
        self.agent_id = self._validate_agent_id(agent_id)
        self.config = config or {}
        
        # Storage path
        storage_root = Path(
            self.config.get("storage_root", "~/.amplifier/memory")
        ).expanduser()
        db_path = storage_root / agent_id / "qdrant.db"
        db_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Qdrant client
        self.client = QdrantClient(path=str(db_path))
        self.collection = "memories"
        
        # Embedding generator
        self.embeddings = EmbeddingGenerator(
            model=self.config.get("embedding_model", "text-embedding-3-small")
        )
        
        # Ensure collection exists
        self._ensure_collection()
    
    def _validate_agent_id(self, agent_id: str) -> str:
        """Validate agent ID (security)."""
        if not re.match(r'^[a-zA-Z0-9_-]+$', agent_id):
            raise ValueError(f"Invalid agent_id: {agent_id}")
        return agent_id
    
    def _ensure_collection(self):
        """Create collection if not exists."""
        collections = {c.name for c in self.client.get_collections().collections}
        if self.collection not in collections:
            self.client.create_collection(
                collection_name=self.collection,
                vectors_config=VectorParams(
                    size=self.embeddings.dimensions,
                    distance=Distance.COSINE
                )
            )
    
    async def store(self, content: str, tags: list[str] = None) -> str:
        """Store memory with embedding."""
        # Generate embedding
        embedding = await self.embeddings.generate(content)
        
        # Create memory
        memory = Memory(
            agent_id=self.agent_id,
            content=content,
            embedding=embedding,
            tags=tags or []
        )
        
        # Store to Qdrant
        self.client.upsert(
            collection_name=self.collection,
            points=[PointStruct(
                id=memory.id,
                vector=memory.embedding,
                payload=memory.dict_for_storage()
            )]
        )
        
        return memory.id
    
    async def search(
        self,
        query: str,
        limit: int = 5,
        since: Optional[datetime] = None
    ) -> list[Memory]:
        """Search memories semantically."""
        # Generate query embedding
        query_embedding = await self.embeddings.generate(query)
        
        # Build filter
        query_filter = None
        if since:
            query_filter = Filter(
                must=[{
                    "key": "timestamp",
                    "range": {"gte": since.isoformat()}
                }]
            )
        
        # Search
        results = self.client.search(
            collection_name=self.collection,
            query_vector=query_embedding,
            limit=limit * 2,  # Over-fetch for ranking
            query_filter=query_filter,
            with_payload=True
        )
        
        # Apply simple ranking
        ranked = self._rank_results(results)
        
        return ranked[:limit]
    
    def _rank_results(self, results) -> list[Memory]:
        """Simple similarity + recency boost."""
        scored = []
        for result in results:
            # Reconstruct memory (embedding not needed for return)
            payload = result.payload
            memory = Memory(
                id=payload["id"],
                agent_id=payload["agent_id"],
                content=payload["content"],
                timestamp=datetime.fromisoformat(payload["timestamp"]),
                embedding=[],  # Don't return embedding to save tokens
                tags=payload.get("tags", [])
            )
            
            # Calculate score
            score = result.score  # Cosine similarity
            
            # Recency boost (20% for last 7 days)
            days_old = (datetime.utcnow() - memory.timestamp).days
            if days_old < 7:
                score *= 1.2
            
            scored.append((score, memory))
        
        # Sort by score
        scored.sort(key=lambda x: x[0], reverse=True)
        return [memory for _, memory in scored]
    
    async def get(self, memory_id: str) -> Optional[Memory]:
        """Get memory by ID."""
        result = self.client.retrieve(
            collection_name=self.collection,
            ids=[memory_id]
        )
        
        if not result:
            return None
        
        payload = result[0].payload
        return Memory(
            id=payload["id"],
            agent_id=payload["agent_id"],
            content=payload["content"],
            timestamp=datetime.fromisoformat(payload["timestamp"]),
            embedding=[],
            tags=payload.get("tags", [])
        )
```

**Validation**:
- [ ] Storage path created correctly
- [ ] Qdrant collection created
- [ ] Agent ID validation works (rejects "../alice")
- [ ] Can store and retrieve by ID

**Time**: 3-4 hours

---

## Day 2: Tool Implementation

### Task 2.1: Tool Module (tools.py)

**File**: `modules/tool-memory-semantic/memory_semantic/tools.py`

**Implementation**:
```python
from amplifier_core import Tool, ToolResult
from amplifier_foundation import get_capability
from typing import Optional
from datetime import datetime

from .storage import MemoryStorage

def mount(coordinator):
    """Mount memory tools."""
    # Get agent identity
    agent_id = get_capability(coordinator, "agent_identity")
    if not agent_id:
        raise ValueError(
            "Memory system requires agent_identity capability. "
            "Set session.capabilities.agent_identity in your config."
        )
    
    # Initialize storage
    config = coordinator.config.get("memory", {})
    storage = MemoryStorage(agent_id, config)
    
    # Define tools
    async def _memory_store(content: str, tags: list[str] = None):
        """Store a memory with semantic embedding."""
        try:
            # Validate
            if not content or len(content) < 1:
                return ToolResult(
                    success=False,
                    error="Content cannot be empty"
                )
            
            if len(content) > 10000:
                return ToolResult(
                    success=False,
                    error="Content too long (max 10,000 chars)"
                )
            
            # Store
            memory_id = await storage.store(content, tags or [])
            
            # Emit event
            await coordinator.emit_event("memory:stored", {
                "agent_id": agent_id,
                "memory_id": memory_id
            })
            
            return ToolResult(
                success=True,
                data={"memory_id": memory_id}
            )
        
        except Exception as e:
            return ToolResult(
                success=False,
                error=f"Failed to store memory: {str(e)}"
            )
    
    async def _memory_search(
        query: str,
        limit: int = 5,
        since: Optional[str] = None
    ):
        """Search memories semantically."""
        try:
            # Validate
            if not query:
                return ToolResult(
                    success=False,
                    error="Query cannot be empty"
                )
            
            if limit > 20:
                limit = 20  # Cap at 20
            
            # Parse since timestamp
            since_dt = None
            if since:
                since_dt = datetime.fromisoformat(since)
            
            # Search
            import time
            start = time.time()
            
            memories = await storage.search(query, limit, since_dt)
            
            query_time_ms = int((time.time() - start) * 1000)
            
            # Emit event
            await coordinator.emit_event("memory:searched", {
                "agent_id": agent_id,
                "query": query,
                "results_count": len(memories),
                "query_time_ms": query_time_ms
            })
            
            # Format results
            results = [
                {
                    "id": m.id,
                    "content": m.content,
                    "timestamp": m.timestamp.isoformat(),
                    "tags": m.tags
                }
                for m in memories
            ]
            
            return ToolResult(
                success=True,
                data={
                    "memories": results,
                    "query_time_ms": query_time_ms
                }
            )
        
        except Exception as e:
            return ToolResult(
                success=False,
                error=f"Failed to search memories: {str(e)}"
            )
    
    # Return tools
    return [
        Tool(
            name="memory_store",
            description="Store a memory with semantic embedding",
            parameters={
                "type": "object",
                "properties": {
                    "content": {
                        "type": "string",
                        "description": "Memory content (1-10,000 chars)"
                    },
                    "tags": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "Optional tags for filtering"
                    }
                },
                "required": ["content"]
            },
            execute=_memory_store
        ),
        Tool(
            name="memory_search",
            description="Search memories semantically using natural language",
            parameters={
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "Natural language search query"
                    },
                    "limit": {
                        "type": "integer",
                        "description": "Max results (default: 5, max: 20)",
                        "default": 5
                    },
                    "since": {
                        "type": "string",
                        "description": "ISO timestamp - only memories after this time"
                    }
                },
                "required": ["query"]
            },
            execute=_memory_search
        )
    ]
```

**Validation**:
- [ ] Tools can be mounted
- [ ] memory_store validates input
- [ ] memory_search returns results
- [ ] Events are emitted
- [ ] Error handling works

**Time**: 3-4 hours

---

### Task 2.2: Integration Test

**File**: `tests/test_integration.py`

**Test scenario**:
```python
import asyncio
from memory_semantic import MemoryStorage

async def test_basic_flow():
    # Create storage
    storage = MemoryStorage("test-agent")
    
    # Store memories
    id1 = await storage.store(
        "Decided to use PostgreSQL for new database",
        tags=["database", "decisions"]
    )
    print(f"âœ“ Stored memory: {id1}")
    
    id2 = await storage.store(
        "API rate limit is 1000 requests per hour",
        tags=["api", "limits"]
    )
    print(f"âœ“ Stored memory: {id2}")
    
    # Search
    results = await storage.search("database decisions")
    print(f"âœ“ Search returned {len(results)} results")
    
    assert len(results) >= 1
    assert "PostgreSQL" in results[0].content
    
    # Get by ID
    memory = await storage.get(id1)
    assert memory is not None
    assert memory.content == "Decided to use PostgreSQL for new database"
    
    print("âœ… All tests passed!")

if __name__ == "__main__":
    asyncio.run(test_basic_flow())
```

**Run**:
```bash
cd modules/tool-memory-semantic
export OPENAI_API_KEY=your-key
python tests/test_integration.py
```

**Validation**:
- [ ] Storage creates database
- [ ] Embeddings are generated
- [ ] Search returns relevant results
- [ ] Get by ID works

**Time**: 1-2 hours

---

## Day 3: Bundle Packaging

### Task 3.1: Bundle Structure

**Create**:
```bash
mkdir -p behaviors
mkdir -p context
mkdir -p docs
```

**Files to create**:
- `bundle.md` - Main bundle manifest
- `behaviors/memory-core.yaml` - Tool behavior
- `context/memory-awareness.md` - Thin context pointer
- `README.md` - User-facing docs

---

### Task 3.2: Bundle Manifest (bundle.md)

**File**: `bundle.md`

```markdown
---
bundle:
  name: agent-memory
  version: 1.0.0
  description: Semantic memory with agent identities (Ruthless V1.0)

includes:
  - bundle: foundation
  - bundle: agent-memory:behaviors/memory-core
---

# Agent Memory System (V1.0)

Semantic memory for Amplifier with named agent identities.

## Quick Start

Set agent identity in your session:

\`\`\`yaml
session:
  capabilities:
    agent_identity: "your-name"
\`\`\`

Then use the tools:

\`\`\`python
# Store
memory_store(content="Your memory here", tags=["tag1"])

# Search
memory_search(query="natural language query")
\`\`\`

@agent-memory:context/memory-awareness.md
```

---

### Task 3.3: Behavior YAML (behaviors/memory-core.yaml)

```yaml
bundle:
  name: memory-core
  version: 1.0.0
  description: Core memory tools (store + search)

tools:
  - module: tool-memory-semantic
    source: ./modules/tool-memory-semantic
    config:
      storage_root: ~/.amplifier/memory
      embedding_model: text-embedding-3-small
      max_query_results: 20

session:
  capabilities:
    required:
      - agent_identity
```

---

### Task 3.4: Context File (context/memory-awareness.md)

**Thin context pointer** (~30 lines):

```markdown
# Memory System Awareness

You have semantic memory capabilities via agent identity.

## Tools Available

- `memory_store(content, tags)` - Store a memory
- `memory_search(query, limit, since)` - Search semantically

## Usage

Store important facts, decisions, and context. Search when you need recall.

Do not over-explain memory mechanics. Use naturally.

**Storage**: `~/.amplifier/memory/{agent_id}/`  
**Cost**: ~$0.00002 per memory (negligible)
```

---

### Task 3.5: README.md

**User-facing documentation**:

```markdown
# Amplifier Agent Memory (V1.0)

Semantic memory system with named agent identities.

## Features

- âœ… Semantic search (not just keywords)
- âœ… Agent identity isolation
- âœ… Vector-based storage (Qdrant)
- âœ… OpenAI embeddings
- âœ… ~$0.02/year cost for 1,000 memories

## Installation

\`\`\`bash
# Install bundle
amplifier bundle add git+https://github.com/USER/amplifier-bundle-agent-memory@main

# Set agent identity
amplifier config set session.capabilities.agent_identity your-name
\`\`\`

## Usage

\`\`\`
User: "Remember this: we use PostgreSQL for new projects"
Agent: âœ“ Stored memory

User: "What's our database standard?"
Agent: Based on your previous decision, we use PostgreSQL.
\`\`\`

## What's NOT in V1.0

- No auto-injection (coming in V1.5 if requested)
- No auto-capture (coming in V2.0 if requested)
- No complex ranking (simple recency boost only)

## Cost

| Memories | Annual Cost |
|----------|-------------|
| 1,000 | $0.02 |
| 5,000 | $0.10 |
| 10,000 | $0.20 |
```

**Time**: 2-3 hours

---

## Validation Checklist

### Functional Requirements
- [ ] Can store memories with agent isolation
- [ ] Can search memories semantically
- [ ] Search returns relevant results
- [ ] Agent namespaces are isolated (security)
- [ ] Errors are handled gracefully

### Non-Functional Requirements
- [ ] Query latency <200ms for 1k memories
- [ ] No data loss or corruption
- [ ] Cost <$0.10/month for typical user
- [ ] Code is <600 lines total

### Integration
- [ ] Bundle loads without errors
- [ ] Tools are available in session
- [ ] Events are emitted correctly
- [ ] Works with foundation bundle

---

## File Summary

**Estimated line counts**:
```
models.py       ~50 lines   (Memory class)
embeddings.py   ~50 lines   (OpenAI wrapper)
storage.py      ~200 lines  (Qdrant + ranking)
tools.py        ~200 lines  (Two tools + mount)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:          ~500 lines
```

**Additional files** (docs, bundle manifests): ~200 lines

**Grand total**: ~700 lines including packaging

---

## Testing Strategy

### Unit Tests (Optional for V1.0)
- Memory model validation
- Agent ID validation
- Embedding generation
- Storage CRUD

### Integration Test (Required)
- End-to-end flow (store â†’ search â†’ verify)
- Namespace isolation
- Error handling

### Manual Testing (Required)
- Deploy to personal environment
- Use for 2-4 weeks
- Track actual usage patterns
- Identify pain points

---

## Deployment

### Personal Deployment

```bash
# 1. Clone repo
git clone https://github.com/USER/amplifier-bundle-agent-memory.git

# 2. Add to my-amplifier bundle
vim ~/.amplifier/bundles/my-amplifier/bundle.md
# Add: - bundle: /path/to/amplifier-bundle-agent-memory/bundle.md

# 3. Set agent identity
vim ~/.amplifier/settings.yaml
# Add:
# session:
#   capabilities:
#     agent_identity: "sam"

# 4. Restart Amplifier
amplifier
```

### Usage Tracking

Track these metrics for 2-4 weeks:

1. **Query frequency**: How often do you search memory?
2. **Query types**: What are you searching for?
3. **Storage patterns**: What do you store?
4. **Pain points**: What's frustrating?

Use this data to decide V1.5/V2.0 features.

---

## V1.5 Decision Points

**Add Context Module IF**:
- You're tired of calling `memory_search` explicitly
- >50% of sessions start with memory query
- You want recent context auto-loaded

**Add Hook Module IF**:
- You forget to store important memories
- You want automatic capture from tool outputs
- Manual storage is tedious

**Improve Ranking IF**:
- Simple recency boost is insufficient
- Have 1k+ memories and search quality degrades
- Can A/B test ranking improvements

**Don't add features until you experience the pain.**

---

## Timeline Summary

- **Day 1**: Storage infrastructure (models, embeddings, storage layer)
- **Day 2**: Tool implementation and integration test
- **Day 3**: Bundle packaging and documentation

**Total**: 1-3 days to ship

**Then**: Use personally for 2-4 weeks, gather data, decide next steps

---

## Success Criteria

V1.0 is successful if:

1. âœ… Can store and search memories
2. âœ… Search quality is acceptable
3. âœ… No major bugs or data loss
4. âœ… Validates hypothesis: "Memory is valuable"

If successful â†’ Plan V1.5/V2.0 based on real usage  
If not successful â†’ Learn why and pivot

---

**Ready to implement. Let's build this! ðŸš€**
